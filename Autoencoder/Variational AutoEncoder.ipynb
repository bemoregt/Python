{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./vae_img'):\n",
    "    os.mkdir('./vae_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    x = x.view(x.size(0),1,28,28)\n",
    "    #print (x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_img(img, name):\n",
    "    img=img.view(1,28,28)\n",
    "    save_img(img, './sample_{}.png'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor/max_tensor\n",
    "    tensor = tensor*(max_value - min_value) + min_value\n",
    "    return torch.round(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform =transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0,1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('./data', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder,self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28,256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU(True))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64,256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256,28*28),\n",
    "            nn.Sigmoid())\n",
    "        # Define forward\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "'''\n",
    "#Convolution autoencoder\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(784,400)\n",
    "        self.fc21 = nn.Linear(400,20)\n",
    "        \n",
    "        self.fc22 = nn.Linear(400,20)\n",
    "        self.fc3 = nn.Linear(20,400)\n",
    "        self.fc4 = nn.Linear(400,784)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "    \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return(eps.mul(std).add_(mu))\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=400, bias=True)\n",
       "  (fc21): Linear(in_features=400, out_features=20, bias=True)\n",
       "  (fc22): Linear(in_features=400, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=400, bias=True)\n",
       "  (fc4): Linear(in_features=400, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE().cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_function = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x,x,mu,logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x,x) #mse loss\n",
    "    KLD_element = mu.pow(2).add(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    return BCE + KLD\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 200.068222\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 60.820198\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 56.998211\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 53.264763\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 48.470757\n",
      "====> Epoch: 0 Average loss: 59.1955\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 49.527145\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 46.030945\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 44.787491\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 45.672977\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 49.175491\n",
      "====> Epoch: 1 Average loss: 46.9194\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 45.553169\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 45.926346\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 46.085052\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 44.592369\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 43.382977\n",
      "====> Epoch: 2 Average loss: 44.5986\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 44.127457\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 44.664948\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 42.982315\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 43.468399\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 43.830853\n",
      "====> Epoch: 3 Average loss: 43.5080\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 42.563560\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 43.445145\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 43.236984\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 42.931168\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 42.341869\n",
      "====> Epoch: 4 Average loss: 42.8449\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 42.793743\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 44.304977\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 40.681278\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 41.193176\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 43.613258\n",
      "====> Epoch: 5 Average loss: 42.4744\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 41.173447\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 40.748283\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 41.550674\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 40.328671\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 43.099468\n",
      "====> Epoch: 6 Average loss: 42.1320\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 41.614548\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 41.699890\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 41.773254\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 42.476730\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 43.154129\n",
      "====> Epoch: 7 Average loss: 41.8713\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 40.199539\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 40.807903\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 40.912796\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 41.483677\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 42.455406\n",
      "====> Epoch: 8 Average loss: 41.6935\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 41.777657\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 41.084152\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 42.911636\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 41.109035\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 43.059006\n",
      "====> Epoch: 9 Average loss: 41.5179\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 43.030674\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 41.024258\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 40.068466\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 42.527939\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 42.670090\n",
      "====> Epoch: 10 Average loss: 41.3551\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 42.883087\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 42.629177\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 39.471222\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 40.847424\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 39.423729\n",
      "====> Epoch: 11 Average loss: 41.2495\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 40.484474\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 40.983307\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 40.700714\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 41.814323\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 41.364220\n",
      "====> Epoch: 12 Average loss: 41.1514\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 40.485497\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 40.948341\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 39.723530\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 41.693592\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 41.293560\n",
      "====> Epoch: 13 Average loss: 41.0412\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 43.088959\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 42.991238\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 39.843239\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 40.343124\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 40.437782\n",
      "====> Epoch: 14 Average loss: 40.9176\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 40.828659\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 39.217270\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 40.886936\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 40.489082\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 42.578526\n",
      "====> Epoch: 15 Average loss: 40.8513\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 39.102760\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 41.298317\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 40.811634\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 39.135769\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 40.903965\n",
      "====> Epoch: 16 Average loss: 40.8007\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 40.235439\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 39.496292\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 40.915428\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 40.371929\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 39.412846\n",
      "====> Epoch: 17 Average loss: 40.7032\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 40.695076\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 40.599266\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 41.929718\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 40.787430\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 39.955135\n",
      "====> Epoch: 18 Average loss: 40.6729\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 42.017750\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 41.038567\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 40.318821\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 41.930824\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 40.352566\n",
      "====> Epoch: 19 Average loss: 40.5951\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 40.196869\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 41.385170\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 39.394188\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 39.579971\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 40.128120\n",
      "====> Epoch: 20 Average loss: 40.5019\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 39.744129\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 41.251244\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 39.835747\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 40.427547\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 39.555161\n",
      "====> Epoch: 21 Average loss: 40.4596\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 40.764946\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 39.863144\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 38.831879\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 39.530373\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 40.694565\n",
      "====> Epoch: 22 Average loss: 40.4285\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 42.686657\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 40.131851\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 41.384731\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 39.503681\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 40.769005\n",
      "====> Epoch: 23 Average loss: 40.3753\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 41.116074\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 40.386856\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 41.507042\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 39.385632\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 42.049313\n",
      "====> Epoch: 24 Average loss: 40.3080\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 39.995197\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 40.827888\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 39.952221\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 40.497520\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 41.849342\n",
      "====> Epoch: 25 Average loss: 40.2466\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 40.349762\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 40.231625\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 39.854713\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 39.086021\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 40.199989\n",
      "====> Epoch: 26 Average loss: 40.1962\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 40.054451\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 40.732277\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 38.780682\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 40.355133\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 38.242363\n",
      "====> Epoch: 27 Average loss: 40.1652\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 40.393749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 40.843956\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 42.929707\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 38.067795\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 39.324825\n",
      "====> Epoch: 28 Average loss: 40.1380\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 40.101845\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 39.571793\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 39.458401\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 41.017693\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 40.413425\n",
      "====> Epoch: 29 Average loss: 40.0772\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 40.807220\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 39.909081\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 40.375530\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 41.292297\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 40.549934\n",
      "====> Epoch: 30 Average loss: 40.0348\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 41.132996\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 41.125149\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 40.904026\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 39.265839\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 41.087334\n",
      "====> Epoch: 31 Average loss: 40.0131\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 39.308113\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 40.092255\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 39.828964\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 40.973110\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 39.935257\n",
      "====> Epoch: 32 Average loss: 39.9733\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 39.870308\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 41.289700\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 41.636513\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 40.154377\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 41.404396\n",
      "====> Epoch: 33 Average loss: 39.9209\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 39.142109\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 41.274620\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 37.883774\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 40.889088\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 40.299126\n",
      "====> Epoch: 34 Average loss: 39.9010\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 40.658859\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 39.758385\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 39.807693\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 39.653259\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 38.434017\n",
      "====> Epoch: 35 Average loss: 39.8421\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 38.702808\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 40.025944\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 38.921047\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 41.108887\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 41.097267\n",
      "====> Epoch: 36 Average loss: 39.8643\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 40.658772\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 39.778042\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 39.559479\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 38.569504\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 39.680862\n",
      "====> Epoch: 37 Average loss: 39.7908\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 39.254047\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 38.454262\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 39.504326\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 42.211670\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 40.337425\n",
      "====> Epoch: 38 Average loss: 39.7595\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 38.873436\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 39.417164\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 39.658695\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 39.006279\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 40.628139\n",
      "====> Epoch: 39 Average loss: 39.7465\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 39.805351\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 40.912281\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 39.027302\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 38.759918\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 39.248081\n",
      "====> Epoch: 40 Average loss: 39.7112\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 40.516003\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 40.203602\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 38.784737\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 39.352585\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 38.824165\n",
      "====> Epoch: 41 Average loss: 39.6734\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 40.210125\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 39.472122\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 39.562603\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 39.347260\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 39.585045\n",
      "====> Epoch: 42 Average loss: 39.6544\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 37.314095\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 38.858189\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 39.595615\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 39.836823\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 38.571133\n",
      "====> Epoch: 43 Average loss: 39.6209\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 37.924187\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 39.393692\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 39.395588\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 37.775833\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 39.349716\n",
      "====> Epoch: 44 Average loss: 39.6089\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 39.546387\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 39.095753\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 40.297493\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 38.997032\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 40.267532\n",
      "====> Epoch: 45 Average loss: 39.5867\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 38.381317\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 40.276085\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 38.024803\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 40.437004\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 39.943878\n",
      "====> Epoch: 46 Average loss: 39.5362\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 39.698952\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 38.864838\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 40.701927\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 41.109299\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 39.027180\n",
      "====> Epoch: 47 Average loss: 39.5329\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 41.404549\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 39.163403\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 39.770149\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 39.212841\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 39.835403\n",
      "====> Epoch: 48 Average loss: 39.5005\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 39.673904\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 39.603386\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 41.225258\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 39.153999\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 38.830536\n",
      "====> Epoch: 49 Average loss: 39.4654\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 39.302120\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 39.590607\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 39.940147\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 37.916725\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 41.309250\n",
      "====> Epoch: 50 Average loss: 39.4337\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 38.446827\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 39.155266\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 39.518940\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 39.852085\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 39.024879\n",
      "====> Epoch: 51 Average loss: 39.4392\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 41.208881\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 39.222816\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 39.689636\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 39.502487\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 41.080250\n",
      "====> Epoch: 52 Average loss: 39.3770\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 39.583836\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 36.977783\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 39.929234\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 39.781155\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 39.209198\n",
      "====> Epoch: 53 Average loss: 39.3744\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 38.828686\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 38.498672\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 38.083122\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 39.563847\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 40.207565\n",
      "====> Epoch: 54 Average loss: 39.3441\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 39.719860\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 39.952633\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 38.970608\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 38.402435\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 38.404106\n",
      "====> Epoch: 55 Average loss: 39.3254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 38.417976\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 40.100990\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 39.600861\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 39.766800\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 40.314648\n",
      "====> Epoch: 56 Average loss: 39.3092\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 38.618359\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 40.449371\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 39.953636\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 38.853462\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 39.693199\n",
      "====> Epoch: 57 Average loss: 39.2978\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 38.647041\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 39.303291\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 39.012657\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 38.761372\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 39.124977\n",
      "====> Epoch: 58 Average loss: 39.2842\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 39.844719\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 38.316460\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 38.849945\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 39.296631\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 40.043800\n",
      "====> Epoch: 59 Average loss: 39.2389\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 41.168247\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 40.573719\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 38.425320\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 41.065727\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 40.373753\n",
      "====> Epoch: 60 Average loss: 39.2184\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 39.392906\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 38.067638\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 39.590912\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 37.178249\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 38.985577\n",
      "====> Epoch: 61 Average loss: 39.1850\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 39.018608\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 38.729126\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 39.067459\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 38.674576\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 39.940796\n",
      "====> Epoch: 62 Average loss: 39.1534\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 39.350441\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 38.759209\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 38.318222\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 38.306541\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 38.804581\n",
      "====> Epoch: 63 Average loss: 39.1694\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 38.726257\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 39.938927\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 38.986759\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 38.193310\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 38.697639\n",
      "====> Epoch: 64 Average loss: 39.1628\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 38.914696\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 36.910545\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 39.070503\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 37.507607\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 40.790264\n",
      "====> Epoch: 65 Average loss: 39.1389\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 39.036110\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 36.683037\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 38.648712\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 37.223526\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 40.254555\n",
      "====> Epoch: 66 Average loss: 39.0920\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 38.726765\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 37.225548\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 38.936882\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 38.874504\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 39.177570\n",
      "====> Epoch: 67 Average loss: 39.0784\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 38.625465\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 39.836845\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 37.747444\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 37.908638\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 39.512566\n",
      "====> Epoch: 68 Average loss: 39.0681\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 38.562462\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 38.891739\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 38.401711\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 39.540295\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 39.539192\n",
      "====> Epoch: 69 Average loss: 39.0602\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 40.356529\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 39.992931\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 41.230858\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 38.663605\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 38.062332\n",
      "====> Epoch: 70 Average loss: 39.0434\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 40.460472\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 38.212559\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 39.507786\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 39.352470\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 41.060905\n",
      "====> Epoch: 71 Average loss: 39.0259\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 38.326366\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 38.537056\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 37.900650\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 38.257179\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 39.125980\n",
      "====> Epoch: 72 Average loss: 39.0293\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 38.377110\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 38.785393\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 38.550850\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 38.916641\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 40.593842\n",
      "====> Epoch: 73 Average loss: 38.9851\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 39.010056\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 38.719238\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 37.492035\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 39.286823\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 38.644936\n",
      "====> Epoch: 74 Average loss: 38.9707\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 38.388252\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 38.993469\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 39.811165\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 38.983765\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 38.155628\n",
      "====> Epoch: 75 Average loss: 39.0017\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 39.439026\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 37.097004\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 39.426308\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 38.326336\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 38.838501\n",
      "====> Epoch: 76 Average loss: 38.9640\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 38.992638\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 38.090759\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 39.973541\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 41.035137\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 40.583920\n",
      "====> Epoch: 77 Average loss: 38.9474\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 38.811096\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 40.034252\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 38.227009\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 38.746899\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 39.112999\n",
      "====> Epoch: 78 Average loss: 38.9209\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 40.763000\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 39.572029\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 39.002953\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 39.405327\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 38.189903\n",
      "====> Epoch: 79 Average loss: 38.9209\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 38.590073\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 38.857502\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 39.012936\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 38.040871\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 38.352081\n",
      "====> Epoch: 80 Average loss: 38.9169\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 37.087494\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 39.946625\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 38.798485\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 39.366341\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 39.286949\n",
      "====> Epoch: 81 Average loss: 38.8629\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 39.570801\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 40.539970\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 40.012508\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 39.267609\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 39.439041\n",
      "====> Epoch: 82 Average loss: 38.8672\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 37.351578\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 38.388115\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 37.390404\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 38.188511\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 39.764244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 83 Average loss: 38.8891\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 38.848965\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 38.761551\n",
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 38.929626\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 38.470779\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 39.719677\n",
      "====> Epoch: 84 Average loss: 38.8344\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 38.293709\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 38.353153\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 38.786720\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 40.660889\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 39.202862\n",
      "====> Epoch: 85 Average loss: 38.8259\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 37.454071\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 38.912170\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 39.492912\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 40.029083\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 39.418365\n",
      "====> Epoch: 86 Average loss: 38.8172\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 40.613663\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 39.009083\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 38.102703\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 37.991692\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 38.008301\n",
      "====> Epoch: 87 Average loss: 38.7961\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 38.242149\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 40.981827\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 39.648163\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 38.014519\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 38.474045\n",
      "====> Epoch: 88 Average loss: 38.8056\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 39.016777\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 39.182098\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 38.763828\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 39.120377\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 37.434807\n",
      "====> Epoch: 89 Average loss: 38.7853\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 38.751152\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 39.758522\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 38.006458\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 39.176933\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 38.281628\n",
      "====> Epoch: 90 Average loss: 38.7698\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 39.136024\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 38.309242\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 38.396332\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 37.318943\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 39.447411\n",
      "====> Epoch: 91 Average loss: 38.7476\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 38.668079\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 39.930981\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 40.245529\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 38.597267\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 39.589954\n",
      "====> Epoch: 92 Average loss: 38.7557\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 39.663021\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 41.082294\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 40.166138\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 40.346405\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 39.183022\n",
      "====> Epoch: 93 Average loss: 38.7377\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 36.483047\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 37.235241\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 39.802498\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 39.027042\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 38.068966\n",
      "====> Epoch: 94 Average loss: 38.7153\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 39.927315\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 38.577209\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 38.716881\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 39.918457\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 37.677570\n",
      "====> Epoch: 95 Average loss: 38.7398\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 38.527977\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 36.993443\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 38.645916\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 39.718925\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 39.360081\n",
      "====> Epoch: 96 Average loss: 38.7424\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 37.332321\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 39.858734\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 37.446922\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 38.975658\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 38.600300\n",
      "====> Epoch: 97 Average loss: 38.6785\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 38.184231\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 39.770336\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 38.728256\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 39.576492\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 38.620811\n",
      "====> Epoch: 98 Average loss: 38.6882\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 38.086098\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 39.758579\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 38.603279\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 35.888103\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 39.591324\n",
      "====> Epoch: 99 Average loss: 38.6645\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        img,_=data\n",
    "        img = img.view(img.size(0),-1)\n",
    "        img = Variable(img)\n",
    "        img = img.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx%100 ==0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
    "                loss.data[0] / len(img)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(dataloader.dataset)))\n",
    "    if epoch % 10 == 0:\n",
    "        save = to_img(recon_batch.cpu().data)\n",
    "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './vae.pth')\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\1st year\\\\Python codes\\\\CIFR Analysis\\\\self contained analysis'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
